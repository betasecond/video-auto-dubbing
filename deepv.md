# DeepV Project Context & Guidelines

> **Generated:** 2026-02-08 (Enhanced with comprehensive codebase analysis)
> **Last Updated:** 2026-02-08
> **Version:** 2.0.0

---

## ğŸ¯ Project Overview

**DeepV (è§†é¢‘è‡ªåŠ¨é…éŸ³ç³»ç»Ÿ)** is a production-grade, AI-powered video localization platform that automatically translates and dubs videos into multiple languages. The system leverages Aliyun's DashScope platform for advanced AI services including:

- **ASR (Automatic Speech Recognition)** - Multi-speaker speech-to-text with emotion detection
- **LLM Translation** - Context-aware translation using Qwen models
- **Voice Cloning TTS** - Real-time voice replication using CosyVoice technology
- **Smart Audio Alignment** - Intelligent speed adjustment to match original timing

**Key Innovation**: Multi-speaker voice cloning with voice ID reuse mechanism - achieving 50x performance improvement by caching voice profiles per task.

---

## ğŸ—ï¸ Technology Stack

### Backend (Python 3.11+)
| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Framework** | FastAPI | 0.109+ | Async REST API server |
| **Database** | PostgreSQL | 14+ | Persistent data storage |
| **ORM** | SQLAlchemy | 2.0.25 | Database abstraction layer |
| **Migration** | Alembic | 1.13.1 | Schema version control |
| **Task Queue** | Celery | 5.3.6 | Async job processing |
| **Message Broker** | Redis | 6.2+ | Celery broker & caching |
| **Package Manager** | uv (Astral) | Latest | Fast Python dependency resolver |
| **Validation** | Pydantic | 2.6.0 | Data validation & serialization |
| **HTTP Client** | httpx | 0.26.0 | Async HTTP requests |
| **Media Processing** | FFmpeg | 4.4+ | Audio/video manipulation |

### Frontend (TypeScript)
| Component | Technology | Version | Purpose |
|-----------|-----------|---------|---------|
| **Framework** | Next.js | 14.1.0 | React full-stack framework (App Router) |
| **Language** | TypeScript | 5.3.3 | Type-safe JavaScript |
| **Styling** | Tailwind CSS | 3.4.1 | Utility-first CSS framework |
| **UI Components** | Radix UI | Latest | Accessible headless components |
| **UI Library** | shadcn/ui | Latest | Pre-built component collection |
| **Icons** | Lucide React | 0.312.0 | Icon library |
| **Form Handling** | React Hook Form | 7.49.3 | Form state management |
| **Validation** | Zod | 3.22.4 | Schema validation |
| **Data Fetching** | SWR | 2.4.0 | React Hooks for data fetching |
| **HTTP Client** | Axios | 1.6.5 | HTTP request library |

### External Services (Aliyun DashScope)
| Service | Model | Purpose |
|---------|-------|---------|
| **ASR** | SenseVoice-v1 | Speech recognition with speaker diarization |
| **LLM** | Qwen-Turbo | Context-aware translation |
| **TTS (System)** | CosyVoice-v1 | Preset voice synthesis (9 voices) |
| **TTS (Clone)** | Qwen3-TTS-VC-Realtime | Voice cloning & synthesis |
| **Storage** | Aliyun OSS | Object storage for media files |

---

## ğŸ“ System Architecture

### High-Level Architecture (Layered)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Presentation Layer                         â”‚
â”‚  Next.js 14 (React 18) + TypeScript + Tailwind CSS             â”‚
â”‚  - Task creation UI (upload form)                               â”‚
â”‚  - Task list & detail pages                                     â”‚
â”‚  - Real-time progress monitoring (SWR polling)                  â”‚
â”‚  - Download result interface                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†• HTTP/REST API
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Application Layer                          â”‚
â”‚  FastAPI (Python 3.11+)                                         â”‚
â”‚  - RESTful API endpoints (/api/v1/tasks, /monitoring)          â”‚
â”‚  - Request validation (Pydantic schemas)                        â”‚
â”‚  - File upload handling (multipart/form-data)                   â”‚
â”‚  - Task orchestration (Celery task chains)                      â”‚
â”‚  - Authentication & CORS middleware                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†• Database & Queue
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Business Logic Layer                       â”‚
â”‚  Services (TaskService, StorageService, VoiceService)          â”‚
â”‚  - Task lifecycle management                                    â”‚
â”‚  - OSS file operations (upload/download/presigned URLs)        â”‚
â”‚  - Voice cloning with cache                                     â”‚
â”‚  - Segment CRUD operations                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†• Async Tasks
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Task Processing Layer                       â”‚
â”‚  Celery Workers (Multi-step Pipeline)                          â”‚
â”‚  1. extract_audio    â†’ FFmpeg audio extraction                  â”‚
â”‚  2. transcribe_audio â†’ DashScope ASR API                        â”‚
â”‚  3. translate_segments â†’ Qwen LLM batch translation             â”‚
â”‚  4. synthesize_audio â†’ TTS with voice cloning                   â”‚
â”‚  5. mux_video        â†’ FFmpeg audio replacement + subtitles     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†• External APIs & Storage
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL   â”‚     Redis      â”‚ Aliyun OSS  â”‚ DashScope APIs   â”‚
â”‚  (Tasks DB)   â”‚ (Celery Queue) â”‚(File Store) â”‚ (AI Services)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Project Directory Structure

```
video-auto-dubbing/
â”œâ”€â”€ backend/                   # Python FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # FastAPI app entry, CORS, lifespan
â”‚   â”‚   â”œâ”€â”€ config.py          # Settings (Pydantic BaseSettings)
â”‚   â”‚   â”œâ”€â”€ database.py        # SQLAlchemy engines, sessions
â”‚   â”‚   â”œâ”€â”€ api/               # REST API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ tasks.py       # Task CRUD endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ monitoring.py  # Health check, stats, Celery inspect
â”‚   â”‚   â”‚   â””â”€â”€ deps.py        # Dependency injection (get_db, services)
â”‚   â”‚   â”œâ”€â”€ models/            # SQLAlchemy ORM models
â”‚   â”‚   â”‚   â”œâ”€â”€ task.py        # Task model (TaskStatus, SubtitleMode)
â”‚   â”‚   â”‚   â””â”€â”€ segment.py     # Segment model (ASR results, translations)
â”‚   â”‚   â”œâ”€â”€ schemas/           # Pydantic validation schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ task.py        # TaskCreate, TaskResponse, TaskDetail
â”‚   â”‚   â”‚   â””â”€â”€ segment.py     # SegmentCreate, SegmentResponse
â”‚   â”‚   â”œâ”€â”€ services/          # Business logic layer
â”‚   â”‚   â”‚   â”œâ”€â”€ task_service.py      # Task CRUD operations
â”‚   â”‚   â”‚   â”œâ”€â”€ storage_service.py   # OSS wrapper (upload/download)
â”‚   â”‚   â”‚   â””â”€â”€ voice_service.py     # Voice cloning with cache
â”‚   â”‚   â”œâ”€â”€ workers/           # Celery tasks
â”‚   â”‚   â”‚   â”œâ”€â”€ celery_app.py  # Celery configuration
â”‚   â”‚   â”‚   â””â”€â”€ tasks.py       # 5-step processing pipeline
â”‚   â”‚   â”œâ”€â”€ integrations/      # External API clients
â”‚   â”‚   â”‚   â”œâ”€â”€ dashscope/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ asr_client.py   # ASR async polling
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ llm_client.py   # OpenAI-compatible translation
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ tts_client.py   # TTS + voice cloning (REST/WebSocket)
â”‚   â”‚   â”‚   â””â”€â”€ oss/
â”‚   â”‚   â”‚       â””â”€â”€ client.py       # Aliyun OSS SDK wrapper
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ ffmpeg.py      # FFmpeg operations (extract, merge, subtitle)
â”‚   â”œâ”€â”€ migrations/            # Alembic migration files
â”‚   â”œâ”€â”€ scripts/               # Utility scripts
â”‚   â”‚   â”œâ”€â”€ check_services.py  # Service health diagnostics
â”‚   â”‚   â””â”€â”€ show_asr.py        # ASR result viewer
â”‚   â”œâ”€â”€ tests/                 # Test suite
â”‚   â””â”€â”€ pyproject.toml         # Project dependencies (uv)
â”‚
â”œâ”€â”€ frontend/                  # Next.js 14 Frontend
â”‚   â”œâ”€â”€ app/                   # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ layout.tsx         # Root layout with providers
â”‚   â”‚   â”œâ”€â”€ page.tsx           # Homepage (hero, features)
â”‚   â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx       # Task list page
â”‚   â”‚   â”‚   â”œâ”€â”€ [id]/page.tsx  # Task detail page
â”‚   â”‚   â”‚   â””â”€â”€ new/page.tsx   # Create task page
â”‚   â”‚   â””â”€â”€ providers.tsx      # Client-side providers
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ upload-form.tsx    # File upload form (react-dropzone)
â”‚   â”‚   â””â”€â”€ ui/                # shadcn/ui components
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts             # Axios client & API functions
â”‚   â”‚   â”œâ”€â”€ types.ts           # TypeScript interfaces
â”‚   â”‚   â”œâ”€â”€ utils.ts           # Helper functions (cn, formatters)
â”‚   â”‚   â””â”€â”€ hooks/
â”‚   â”‚       â””â”€â”€ use-tasks.ts   # SWR hooks for data fetching
â”‚   â””â”€â”€ package.json           # Dependencies & scripts
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ guide/                 # User guides
â”‚   â”œâ”€â”€ architecture/          # Architecture docs
â”‚   â””â”€â”€ api/                   # API documentation
â”‚
â”œâ”€â”€ docker-compose.v2.yml      # Docker Compose configuration
â””â”€â”€ .env                       # Environment variables (not in git)
```

---

## ğŸ”„ Video Dubbing Workflow (5-Step Pipeline)

### Step 1: Extract Audio (`extract_audio_task`)

**Purpose**: Separate audio from video

**Actions:**
1. Download video from OSS to temp directory
2. Run FFmpeg: `ffmpeg -i video.mp4 -vn -acodec pcm_s16le -ar 16000 -ac 1 audio.wav`
3. Extract video metadata (duration, resolution)
4. Upload extracted audio to OSS
5. Update task: `extracted_audio_path`, `video_duration_ms`

**Technology:** FFmpeg (PCM 16kHz mono WAV)

---

### Step 2: Transcribe Audio (`transcribe_audio_task`)

**Purpose**: Speech-to-text with speaker diarization

**Actions:**
1. Generate OSS presigned URL (1-hour expiry)
2. Submit async ASR task to DashScope:
   ```python
   Transcription.async_call(
       model="sensevoice-v1",
       file_urls=[audio_url],
       enable_speaker_diarization=True,  # Multi-speaker detection
       disfluency_removal_enabled=True   # Remove filler words
   )
   ```
3. Poll for completion (2s interval, 300s timeout)
4. Parse ASR results:
   - Extract segments with timestamps
   - Identify speakers (`speaker_id`)
   - Filter out empty/punctuation-only segments
5. Create Segment records in database

**Output:**
```json
{
  "segments": [
    {
      "speaker_id": "speaker_0",
      "start_time_ms": 0,
      "end_time_ms": 3000,
      "text": "Hello everyone",
      "emotion": "neutral",
      "confidence": 0.95
    }
  ]
}
```

**Technology:** DashScope SenseVoice (Aliyun ASR)

---

### Step 3: Translate Segments (`translate_segments_task`)

**Purpose**: Context-aware translation

**Actions:**
1. Fetch all segments for task
2. **Full-text translation** (preserving context):
   - Concatenate all segments with `[index]` markers
   - Send to Qwen LLM with custom prompt
   - Parse translated output back to individual segments
3. **Fallback**: If full-text fails, translate segment-by-segment
4. Update `translated_text` for each segment

**Example:**
```
Input:
[0] å¤§å®¶å¥½,æˆ‘æ˜¯ä¸»æŒäººã€‚
[1] ä»Šå¤©æˆ‘ä»¬è®¨è®ºäººå·¥æ™ºèƒ½ã€‚

LLM Output:
[0] Hello everyone, I'm the host.
[1] Today we're discussing artificial intelligence.
```

**Technology:** DashScope Qwen-Turbo (OpenAI-compatible API)

---

### Step 4: Synthesize Audio (`synthesize_audio_task`)

**Purpose**: Text-to-speech with voice cloning

**Actions:**
1. **Group segments by speaker_id**:
   ```python
   {
     "speaker_0": [segment_1, segment_3],
     "speaker_1": [segment_2]
   }
   ```

2. **Voice enrollment** (per speaker, cached):
   - Extract all audio clips for speaker
   - Merge into 10-20s sample
   - Call `TTSClient.enroll_voice()` â†’ returns `voice_id` (vc_xxx)
   - Cache: `{speaker_id â†’ voice_id}` (reuse across segments)

3. **Synthesize each segment**:
   - Use corresponding `voice_id` for TTS
   - Generate MP3 audio
   - Upload to OSS: `task_{id}/segments/segment_{index}.mp3`
   - Update segment: `voice_id`, `audio_path`

**Performance Optimization**: Voice ID reuse reduces API calls by 50x for multi-speaker videos.

**Technology:**
- **Voice Cloning**: Qwen3-TTS-VC-Realtime (WebSocket API)
- **System Voices**: CosyVoice-v1 (9 preset voices, fallback)

---

### Step 5: Mux Video (`mux_video_task`)

**Purpose**: Merge audio segments and replace video track

**Actions:**
1. Download all segment audio files
2. **Smart audio merging**:
   - Calculate time slots (avoid overlaps)
   - Apply speed adjustment if TTS audio exceeds slot (max 4x)
   - Use FFmpeg `adelay` filter to position audio on timeline
3. **Subtitle generation** (if enabled):
   - Create ASS file with dual-language subtitles
   - Upload to OSS
4. **Video composition**:
   - **External subtitles**: `ffmpeg -i video -i audio -c:v copy -c:a aac -map 0:v -map 1:a output.mp4` (fast, video copy)
   - **Burned subtitles**: `ffmpeg -i video -i audio -vf "ass='subtitle.ass'" -c:v libx264 -c:a aac output.mp4` (slow, re-encode)
5. Upload final video to OSS
6. Update task status to `COMPLETED`

**Technology:** FFmpeg (audio mixing, subtitle overlay, video encoding)

---

## ğŸ—„ï¸ Database Schema

### Tasks Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID (PK) | Primary key |
| `title` | String(255) | Task title |
| `source_language` | String(10) | Source language code (zh, en, etc.) |
| `target_language` | String(10) | Target language code |
| `status` | Enum | TaskStatus (pending, extracting, transcribing, translating, synthesizing, muxing, completed, failed) |
| `current_step` | String(20) | Current processing step |
| `progress` | Integer (0-100) | Progress percentage |
| `error_message` | Text | Error details if failed |
| `subtitle_mode` | Enum | SubtitleMode (NONE, EXTERNAL, BURN) |
| `input_video_path` | String(500) | OSS path to input video |
| `extracted_audio_path` | String(500) | OSS path to extracted audio |
| `output_video_path` | String(500) | OSS path to final video |
| `subtitle_file_path` | String(500) | OSS path to subtitle file (.ass) |
| `video_duration_ms` | Integer | Video duration in milliseconds |
| `segment_count` | Integer | Number of segments |
| `celery_task_id` | String(100) | Celery task ID for tracking |
| `created_at` | DateTime | Creation timestamp |
| `updated_at` | DateTime | Last update timestamp |
| `completed_at` | DateTime | Completion timestamp |

**Indexes:**
- `ix_tasks_id` (UUID)
- `ix_tasks_status` (for filtering)
- `ix_tasks_created_at` (for sorting)

### Segments Table

| Column | Type | Description |
|--------|------|-------------|
| `id` | UUID (PK) | Primary key |
| `task_id` | UUID (FK â†’ tasks.id) | Parent task ID (CASCADE DELETE) |
| `segment_index` | Integer | Sequential index |
| `start_time_ms` | Integer | Start time in milliseconds |
| `end_time_ms` | Integer | End time in milliseconds |
| `original_text` | Text | ASR transcription |
| `translated_text` | Text | LLM translation |
| `speaker_id` | String(50) | Speaker identifier (from ASR) |
| `emotion` | String(20) | Emotion tag (from ASR) |
| `confidence` | Float | Confidence score |
| `voice_id` | String(100) | Voice cloning ID (vc_xxx) - **CACHED FOR REUSE** |
| `audio_path` | String(500) | OSS path to synthesized audio |
| `created_at` | DateTime | Creation timestamp |
| `updated_at` | DateTime | Last update timestamp |

**Indexes:**
- `ix_segments_id` (UUID)
- `ix_segments_task_id` (foreign key)
- `idx_task_segment` (task_id, segment_index) - UNIQUE

**Relationships:**
- 1 Task â†’ N Segments (one-to-many)
- Cascade delete: deleting a task removes all segments

---

## ğŸ”Œ API Endpoints

### Task Management

| Method | Endpoint | Description | Request | Response |
|--------|----------|-------------|---------|----------|
| POST | `/api/v1/tasks` | Create dubbing task | `multipart/form-data` (video, source_language, target_language, title?, subtitle_mode?) | `TaskResponse` |
| GET | `/api/v1/tasks` | List tasks | Query: page, page_size, status? | `TaskListResponse` |
| GET | `/api/v1/tasks/{id}` | Get task details | Path: task_id | `TaskDetail` (with segments) |
| DELETE | `/api/v1/tasks/{id}` | Delete task | Path: task_id | 204 No Content |
| GET | `/api/v1/tasks/{id}/result` | Get download URLs | Path: task_id | `{download_url, subtitle_url?, expires_in}` |
| GET | `/api/v1/tasks/{id}/subtitle` | Get subtitle URL | Path: task_id | `{subtitle_url, expires_in}` |

### Monitoring

| Method | Endpoint | Description | Response |
|--------|----------|-------------|----------|
| GET | `/api/v1/monitoring/health` | Health check | `{status, services: {database, redis, ffmpeg}, version}` |
| GET | `/api/v1/monitoring/stats` | System stats | `{tasks: {total, by_status}, workers: {active, registered}}` |
| GET | `/api/v1/monitoring/celery/inspect` | Celery worker status | Worker inspection data |

---

## âš™ï¸ Configuration & Environment Variables

### Required Environment Variables

```bash
# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=dubbing
DB_USER=dubbing
DB_PASSWORD=<secure-password>

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=<optional>
REDIS_DB=0

# Aliyun OSS
OSS_ENDPOINT=oss-cn-shanghai.aliyuncs.com
OSS_BUCKET=your-bucket-name
OSS_ACCESS_KEY_ID=LTAI***
OSS_ACCESS_KEY_SECRET=***
OSS_PUBLIC_DOMAIN=cdn.example.com  # Optional CDN
OSS_PREFIX=videos/

# Aliyun DashScope
DASHSCOPE_API_KEY=sk-***

# ASR Settings
ASR_MODEL=sensevoice-v1
ASR_LANGUAGE_HINTS=["zh", "en"]

# LLM Settings
DASHSCOPE_LLM_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
DASHSCOPE_LLM_MODEL=qwen-turbo
LLM_MAX_TOKENS=2000

# TTS Settings
TTS_MODEL=qwen3-tts-vc-realtime-2026-01-15  # or cosyvoice-v1
TTS_VOICE=longxiaochun  # System voice (cosyvoice-v1 only)
TTS_FORMAT=mp3

# Application
DEBUG=false
LOG_LEVEL=INFO
CORS_ORIGINS=http://localhost:3000,http://localhost

# Worker
WORKER_CONCURRENCY=4
TASK_TIMEOUT=3600
```

### Frontend Environment

```bash
NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1
```

---

## ğŸš€ Development Commands

### Environment Management

**Python Package Management:**
```bash
# We use `uv` for Python package and environment management
cd backend

# Create virtual environment
uv venv

# Install dependencies
uv sync

# Install in editable mode with dev dependencies
uv pip install -e ".[dev]"

# Run scripts in the environment
uv run python scripts/check_services.py
```

### Backend Development

```bash
cd backend

# Run dev server (auto-reload)
uv run uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Run Celery worker
celery -A app.workers.celery_app worker --loglevel=info --concurrency=4

# Database migrations
alembic upgrade head                          # Apply migrations
alembic revision --autogenerate -m "description"  # Create migration
alembic downgrade -1                          # Rollback one version

# Run tests
pytest
pytest --cov=app tests/                       # With coverage
pytest -v -s tests/test_integrations.py       # Specific test file

# Format code
black app/
ruff app/ --fix

# Type checking
mypy app/

# Service diagnostics
python scripts/check_services.py
```

### Frontend Development

```bash
cd frontend

# Install dependencies
npm install

# Run dev server (hot reload)
npm run dev

# Build for production
npm run build

# Start production server
npm run start

# Lint & type check
npm run lint
npm run type-check

# Component development
npm run storybook  # If configured
```

### Docker Compose

```bash
# Start all services
docker-compose -f docker-compose.v2.yml up -d

# View logs
docker-compose logs -f
docker-compose logs -f api       # Specific service
docker-compose logs -f worker

# Scale workers
docker-compose up -d --scale worker=8

# Restart services
docker-compose restart api worker

# Stop services
docker-compose down

# Stop and remove volumes
docker-compose down -v
```

---

## ğŸ§  Key Patterns & Conventions

### 1. Async Database Sessions (Dependency Injection)

```python
# Using FastAPI dependency injection
async def get_db() -> AsyncGenerator[AsyncSession, None]:
    async with AsyncSessionLocal() as session:
        try:
            yield session
            await session.commit()
        except Exception:
            await session.rollback()
            raise
        finally:
            await session.close()

# Usage in API endpoints
@router.get("/tasks/{task_id}")
async def get_task(
    task_id: UUID,
    db: AsyncSession = Depends(get_db)
):
    task = await TaskService.get_task(db, task_id)
    return task
```

### 2. Celery Task Chains (Sequential Processing)

```python
# Chain tasks in sequence
pipeline = chain(
    extract_audio_task.s(task_id),
    transcribe_audio_task.s(task_id),
    translate_segments_task.s(task_id),
    synthesize_audio_task.s(task_id),
    mux_video_task.s(task_id),
).apply_async()

# Store Celery task ID for tracking
task.celery_task_id = pipeline.id
```

### 3. Voice ID Caching (Multi-speaker Optimization)

```python
# Cache structure: {speaker_id â†’ voice_id}
voice_cache = {}

for speaker_id in speakers:
    if speaker_id in voice_cache:
        voice_id = voice_cache[speaker_id]  # Reuse existing voice ID
    else:
        voice_id = enroll_voice(speaker_id)  # Clone voice once
        voice_cache[speaker_id] = voice_id

    # Use cached voice_id for all segments of this speaker
    synthesize_segment(segment, voice_id)

# Performance: 50x faster for multi-speaker videos
```

### 4. FFmpeg Smart Speed Adjustment

```python
# Calculate speed ratio
actual_duration_ms = get_audio_duration(audio_path)
target_duration_ms = segment.end_time_ms - segment.start_time_ms
speed_ratio = actual_duration_ms / target_duration_ms

# Apply atempo filter (range 0.5-2.0, chain if >2x)
if speed_ratio > 2.0:
    # Chain multiple atempo filters
    filters = ["atempo=2.0", f"atempo={speed_ratio/2.0}"]
else:
    filters = [f"atempo={speed_ratio}"]

filter_str = ",".join(filters)
# ffmpeg -i audio.wav -filter:a "atempo=2.0,atempo=1.5" output.wav
```

### 5. Pydantic Settings Configuration

```python
from pydantic_settings import BaseSettings, SettingsConfigDict

class Settings(BaseSettings):
    model_config = SettingsConfigDict(
        env_file=[".env"],
        case_sensitive=False,
        extra="ignore"
    )

    # Database
    db_host: str = Field(default="localhost", alias="DB_HOST")
    db_port: int = Field(default=5432, alias="DB_PORT")

    @property
    def database_url(self) -> str:
        return f"postgresql+asyncpg://{self.db_user}:{self.db_password}@{self.db_host}:{self.db_port}/{self.db_name}"

settings = Settings()
```

### 6. SWR Data Fetching (Frontend)

```typescript
// Auto-revalidating hook with polling
export function useTask(taskId: string | null) {
  const { data, error, mutate } = useSWR(
    taskId ? `/tasks/${taskId}` : null,
    () => taskId ? api.getTask(taskId) : null,
    {
      refreshInterval: 2000,  // Poll every 2s
      revalidateOnFocus: true,
      revalidateOnReconnect: true,
    }
  );

  return {
    task: data,
    isLoading: !error && !data,
    isError: error,
    mutate
  };
}
```

---

## âš ï¸ Common Gotchas & Solutions

### 1. TTS Model Confusion

**Issue**: Using system voice names with voice cloning model

```python
# âŒ WRONG
client = TTSClient(model="qwen3-tts-vc-realtime-2026-01-15")
audio = client.synthesize("Hello", voice="longxiaochun")
# â†’ ValueError: requires voice_id (vc_xxx format)

# âœ… CORRECT
client = TTSClient(model="qwen3-tts-vc-realtime-2026-01-15")
voice_id = client.enroll_voice("sample.wav")  # Returns vc_abc123
audio = client.synthesize("Hello", voice=voice_id)
```

### 2. FFmpeg Path Escaping

**Issue**: Special characters in file paths break filter syntax

```python
# Subtitle filter requires careful escaping
subtitle_path = "C:\\Users\\video\\subtitle's.ass"

# Escape for FFmpeg filter
escaped = subtitle_path.replace("\\", "/").replace(":", "\\:").replace("'", "'\\''")

# Use in filter: ass='escaped/path'
cmd = ["ffmpeg", "-i", "video.mp4", "-vf", f"ass='{escaped}'", "output.mp4"]
```

### 3. Async Event Loop in Celery

**Issue**: Celery workers need event loop management

```python
def _run_async(coro):
    """Reuse event loop across Celery tasks"""
    loop = getattr(_run_async, "_loop", None)
    if loop is None or loop.is_closed():
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        _run_async._loop = loop
    return loop.run_until_complete(coro)

# Usage in Celery task
@celery_app.task
def process_task(task_id: str):
    return _run_async(async_function(task_id))
```

### 4. Subtitle Mode Enum Mismatch

**Frontend sends lowercase**: `subtitle_mode=external`
**Backend expects uppercase**: `SubtitleMode.EXTERNAL`

**Solution**: API endpoint converts automatically:
```python
subtitle_mode_enum = SubtitleMode(subtitle_mode.upper())
```

### 5. Audio Timeline Overlapping

**Issue**: Overlapping segments cause audio artifacts

**Solution**: Smart speed adjustment

```python
for i, segment in enumerate(segments):
    # Calculate next segment's start
    next_start = segments[i+1].start_time_ms if i+1 < len(segments) else video_duration_ms

    # Maximum time slot available
    max_slot_ms = next_start - segment.start_time_ms

    # If TTS audio exceeds slot, speed it up
    if tts_audio_duration > max_slot_ms:
        speed_ratio = tts_audio_duration / max_slot_ms
        adjust_speed(tts_audio, speed=speed_ratio)
```

---

## ğŸ§ª Testing Strategy

### Backend Tests (`backend/tests/`)

**Structure:**
```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_api/                # API endpoint tests
â”‚   â”œâ”€â”€ test_tasks.py        # Task CRUD tests
â”‚   â””â”€â”€ test_monitoring.py   # Health check tests
â”œâ”€â”€ test_workers/            # Celery task tests
â”‚   â””â”€â”€ test_pipeline.py     # Pipeline integration tests
â”œâ”€â”€ test_integrations.py     # External API mocks
â””â”€â”€ test_oss.py              # OSS client tests
```

**Testing Tools:**
- `pytest` - Test framework
- `pytest-asyncio` - Async test support
- `pytest-cov` - Coverage reporting
- `httpx` - Async HTTP test client

**Example Test:**
```python
@pytest.mark.asyncio
async def test_create_task(client, db_session):
    with open("tests/fixtures/sample.mp4", "rb") as f:
        video_bytes = f.read()

    response = await client.post(
        "/api/v1/tasks",
        files={"video": ("test.mp4", video_bytes, "video/mp4")},
        data={
            "source_language": "zh",
            "target_language": "en",
            "title": "Test Video"
        }
    )

    assert response.status_code == 201
    data = response.json()
    assert data["status"] == "pending"
    assert data["source_language"] == "zh"
    assert data["target_language"] == "en"
```

**Coverage Goals:**
- API endpoints: 80%+
- Services: 75%+
- Workers: 60%+
- Overall: 70%+

---

## ğŸ­ Deployment Architecture

### Docker Compose Services

```yaml
services:
  # PostgreSQL 15
  db:
    image: postgres:15
    environment:
      POSTGRES_DB: dubbing
      POSTGRES_USER: dubbing
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U dubbing"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis 7
  redis:
    image: redis:7-alpine
    command: redis-server --requirepass ${REDIS_PASSWORD} --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5

  # FastAPI Backend
  api:
    build: ./backend
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://dubbing:${DB_PASSWORD}@db:5432/dubbing
      - REDIS_HOST=redis
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY}
      - OSS_ACCESS_KEY_ID=${OSS_ACCESS_KEY_ID}
      - OSS_ACCESS_KEY_SECRET=${OSS_ACCESS_KEY_SECRET}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  # Celery Worker
  worker:
    build: ./backend
    environment:
      - DATABASE_URL=postgresql+asyncpg://dubbing:${DB_PASSWORD}@db:5432/dubbing
      - REDIS_HOST=redis
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - DASHSCOPE_API_KEY=${DASHSCOPE_API_KEY}
      - OSS_ACCESS_KEY_ID=${OSS_ACCESS_KEY_ID}
      - OSS_ACCESS_KEY_SECRET=${OSS_ACCESS_KEY_SECRET}
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./backend:/app
    command: celery -A app.workers.celery_app worker --loglevel=info --concurrency=4

  # Next.js Frontend
  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://api:8000/api/v1
    depends_on:
      - api
    volumes:
      - ./frontend:/app
      - /app/node_modules
    command: npm run dev

volumes:
  postgres_data:
  redis_data:
```

---

## ğŸ“š Documentation & Resources

### Project Documentation
- **[README.md](README.md)**: Project overview (Chinese)
- **[README_EN.md](README_EN.md)**: Project overview (English)
- **[docs/guide/start-here.md](docs/guide/start-here.md)**: Getting started guide
- **[docs/guide/quickstart.md](docs/guide/quickstart.md)**: Detailed deployment guide
- **[docs/architecture/system-overview.md](docs/architecture/system-overview.md)**: Architecture overview
- **[docs/architecture/optimization.md](docs/architecture/optimization.md)**: Voice cloning & alignment optimization
- **[docs/guide/frontend.md](docs/guide/frontend.md)**: Frontend development guide
- **[docs/api/backend-api.md](docs/api/backend-api.md)**: API documentation

### External Resources
- **Aliyun DashScope**: https://help.aliyun.com/zh/dashscope/
- **FastAPI**: https://fastapi.tiangolo.com/
- **Next.js 14**: https://nextjs.org/docs
- **Celery**: https://docs.celeryq.dev/
- **SQLAlchemy 2.0**: https://docs.sqlalchemy.org/
- **shadcn/ui**: https://ui.shadcn.com/

---

## ğŸ“ Implementation Guidance

### For Adding New Features

**New API Endpoint:**
1. Add route in `/backend/app/api/tasks.py`
2. Create Pydantic schema in `/backend/app/schemas/`
3. Add service method in `/backend/app/services/`
4. Update frontend API client in `/frontend/lib/api.ts`
5. Add TypeScript type in `/frontend/lib/types.ts`

**New Processing Step:**
1. Add Celery task in `/backend/app/workers/tasks.py`
2. Insert into pipeline chain in task creation
3. Update task status enum if needed
4. Add progress tracking in frontend

**New External API Integration:**
1. Create client in `/backend/app/integrations/`
2. Wrap with service layer
3. Add configuration in `config.py`
4. Add unit tests

**New UI Component:**
1. Add component to `/frontend/components/`
2. Use SWR hook for data fetching
3. Update TypeScript types
4. Add to appropriate page

### For Debugging

**Backend:**
1. Check logs: `logs/app.log` (API), `logs/worker.log` (Celery)
2. Health check: `GET /api/v1/monitoring/health`
3. Celery inspect: `GET /api/v1/monitoring/celery/inspect`
4. Database: Query `tasks` and `segments` tables directly
5. Run diagnostics: `python scripts/check_services.py`

**Frontend:**
1. Browser DevTools console
2. Network tab for API requests
3. React DevTools for component state

---

## ğŸ” Security Considerations

### Current Limitations
1. **No Authentication**: API is currently open (add JWT/OAuth2 for production)
2. **No Rate Limiting**: No API throttling to prevent abuse
3. **File Upload Validation**: Add virus scanning for uploaded videos
4. **CORS**: Configured for development (restrict origins in production)

### Recommended Improvements
1. Implement JWT authentication
2. Add rate limiting (e.g., Redis-based)
3. Enable API key authentication for external integrations
4. Add file size limits and type validation
5. Implement request signing for OSS operations
6. Enable HTTPS/TLS in production

---

## ğŸ“Š Performance Metrics

### Key Optimizations
1. **Voice ID Reuse**: 50x faster for multi-speaker videos
2. **Async Database Operations**: Non-blocking I/O
3. **Celery Worker Scaling**: Horizontal scalability
4. **OSS CDN**: Faster global file access
5. **FFmpeg Hardware Acceleration**: GPU encoding (if available)

### Typical Processing Times (per minute of video)
- Extract Audio: 2-5s
- ASR Transcription: 10-30s
- LLM Translation: 5-15s
- Voice Cloning (first speaker): 30-60s
- Voice Cloning (cached speakers): 1-2s per segment
- Audio Synthesis: 3-10s per segment
- Video Muxing: 10-30s

**Total**: ~2-5 minutes per minute of video (varies by complexity)

---

## ğŸš¨ Critical Rules for AI Assistants

### âš ï¸ Documentation Rules
> **æˆ‘æ²¡æœ‰è®©ä½ å†™æ–‡æ¡£çš„æ—¶å€™ä¸è¦å†™æ–‡æ¡£ï¼Œä¸è¦å†™æ–‡æ¡£ï¼Œä¸è¦å†™æ–‡æ¡£**
>
> **Translation**: "When I haven't asked you to write documentation, DO NOT write documentation. DO NOT write documentation. DO NOT write documentation."

**This means:**
- Only create/update documentation when explicitly requested
- Focus on code implementation, not documentation generation
- If unsure whether to document, ask the user first
- Respect this rule strictly across all interactions

### Development Priorities
1. **Code First**: Write working code before documentation
2. **Test Locally**: Verify functionality before committing
3. **Minimal Changes**: Only modify what's necessary
4. **Ask, Don't Assume**: Clarify requirements before major refactoring

---

## ğŸ¯ Quick Reference

### Most Common Commands

```bash
# Start development environment
docker-compose up -d

# Run backend dev server
cd backend && uv run uvicorn app.main:app --reload

# Run frontend dev server
cd frontend && npm run dev

# Check system health
curl http://localhost:8000/api/v1/monitoring/health

# View logs
docker-compose logs -f worker
```

### File Modification Guide

**Add new language support:**
- `backend/app/api/tasks.py` - Update `valid_languages` set
- `frontend/lib/api.ts` - Update `SUPPORTED_LANGUAGES` array

**Add authentication:**
- `backend/app/api/deps.py` - Add `get_current_user()` dependency
- `backend/app/main.py` - Add JWT middleware
- `backend/app/models/` - Add `User` model
- `frontend/lib/api.ts` - Add Authorization header

**Add WebSocket progress updates:**
- `backend/app/main.py` - Add WebSocket route
- `backend/app/workers/tasks.py` - Emit progress events
- `frontend/lib/hooks/use-task-ws.ts` - Create WebSocket hook
- `frontend/app/tasks/[id]/page.tsx` - Replace SWR polling

---

## ğŸ“ˆ Refactoring Status (as of Feb 2026)

**Completed:**
- âœ… Transitioned from local GPU inference to Aliyun DashScope APIs
- âœ… Backend core implemented (FastAPI + SQLAlchemy + Celery)
- âœ… Database schema designed (tasks + segments)
- âœ… 5-step processing pipeline operational
- âœ… Voice cloning with cache optimization
- âœ… Smart audio timeline management
- âœ… Subtitle generation (external/burned)
- âœ… Frontend basic UI (Next.js + shadcn/ui)
- âœ… Docker Compose deployment setup

**In Progress:**
- ğŸš§ Frontend integration (task list, detail pages)
- ğŸš§ Real-time progress updates (WebSocket)
- ğŸš§ Error handling improvements
- ğŸš§ Test coverage expansion

**Planned:**
- ğŸ“‹ Authentication & authorization
- ğŸ“‹ Rate limiting & security hardening
- ğŸ“‹ Monitoring & observability (Prometheus/Grafana)
- ğŸ“‹ CDN integration for OSS
- ğŸ“‹ Batch processing support
- ğŸ“‹ Multi-language UI (i18n)

---

**Generated by DeepV Code AI Assistant**
**Last Updated:** 2026-02-08
**Project Version:** 2.0.0

## DeepV Code Added Memories
- DEEPV.md generated by /init command on 2026-02-08 (enhanced comprehensive analysis version with full codebase exploration, architecture breakdown, workflow documentation, API reference, and development guidelines)
